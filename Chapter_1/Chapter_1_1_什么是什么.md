## 彼之甘露，我之毒药

我们都知道，计算机非常善于做一些计算的任务，类似31233242*5431354234这种计算，以如今的计算能力，连秒秒钟都不需要，但是如果让人类去做这个计算呢？就算是世界心算冠军也没法拍着胸脯说自己能够在1s内算出结果吧。

但是我们现在换一种方式，给出一张图片让人和计算机分别去认出这张图片中包含什么，正常的人类是很容易能够认出图片中有些什么的，但是这对计算机来说就没那么容易了，事实上让计算机去识别一张图片中到底包含了什么这个任务的难度远远超过我们的想象。

一般来说我们去认出图片中有些什么，理解人类说话这些任务都是需要人类的智能的，我们希望能让计算机也拥有这些能力来帮助人类完成一些工作。

考虑到计算机的原理与人类大相径庭，所以人工智能的任务是找一个新的方法或算法来解决我们上述的任务。

## 举一个例子

让我们想象有这么一台机器，它可以获取到问题，在内部做一些“思考”然后输出答案。

好吧，让我们把这个例子举的具体一点。

现在有一台机器，它的作用是把公里转换成英里，如下图所示

现在假设我们并不知道公里与英里的换算公式，我们唯一知道的信息是它们之间的关系是线性的。线性的意义就是：如果我的输入翻倍，那么我的输出也会翻倍。

知道这层关系让我们能有机会去猜测出这两者中的神秘联系，就是：英里=公里 * C，而C是一个常数，我们的任务就是要算出这个常数究竟是多少。

当然我们不能瞎猜这两者的关系，首先我们会需要一些真实的数据作为我们预测的依据。

| 序号   | 公里   | 英里     |
| ---- | ---- | ------ |
| 1    | 0    | 0      |
| 2    | 100  | 62.137 |

数据有了，那么我们怎么开始呢？

给C一个随机的值是一个好的方法，我们也没有其它好的方法去定义猜测的初始值是多少。

现在我们就把C的值设置为0.5试一下，看看结果怎么样。

看起来效果没有差到离谱，但是也没有好到哪里去。我们知道真实的值是62.137，他们之间的差称之为误差。对于设置的0.5常数，我们的误差是62.137-50=12.137

我们知道我们的预测不正确，然后呢？

我们有了误差值，可以把它用来调整我们的常量，另外，我们知道输入输出之间是一种线性的关系，那么我们增加常量C的值就可以增加输出了。

现在我们把C增加到0.6，看一下输出，变成了60，与我们的真实输出比较一下，误差变成了2.137。可喜的是，误差变小了，证明我们的选择是对的。

好了，我们现在做的事情证明我们一直在做着对的事情，那就继续做下去吧，我们接着把c调整到0.7看看发生了什么？

误差变成了-7.863！这个与我们上一个误差2.137对比一下误差反而变大了！证明了一件事：我们步子迈的太大，扯着蛋了。

好吧，至少我们证明了一件事，c等于0.6的时候比c等于0.7更接近我们的真实需求。

如果我们没有什么追求的话，事情确实可以这么结束了，我们找到一个还算可以的参数来对应英里与公里的转换关系。但是，让我们更进一步吧只是步子不再迈的这么大了。

我们重新定义c的值为0.61，发现误差比0.6又缩小了一些，变成了1.137。这个例子至少教会我们两件事

1. 使用误差来评估学习
2. 适度调整的度很重要

其实这个预测机很接近神经网络的本质了，我们去训练模型，使得它越来越接近正确的答案。

在这个例子里我们也可以发现，我们并没有一蹴而就的解决这个问题，他并不像我们在学校里拿着公示去套答案，整个过程一直在不断的试错，不断的接近正确的答案。

现在回顾一下我们这一小节的关键点：

- 所有的计算机系统都有一个输入，输出以及一个或多个计算节点，神经网络也不例外
- 当我们不知道其中运行的机制时，可以去建立一个模型，其中包括一些我们可以调节的参数。就像这个上面那个预测机，我们不知道如何把公里转换成英里，但我们可以用一个线性函数作为模型来调整
- 调整参数的一个好方法就是利用误差来对比